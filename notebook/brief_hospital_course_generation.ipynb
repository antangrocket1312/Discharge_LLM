{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1a0777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ee905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import random\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c2597",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e778a17e",
   "metadata": {},
   "source": [
    "## Merge and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4abeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_dfs_no_dup_cols(df1, df2, merge_col):\n",
    "    cols_to_use = df2.columns.difference(df1.columns).tolist() + merge_col\n",
    "    return df1.merge(df2[cols_to_use], on=merge_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81f353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "for subset in ['train', 'valid', 'test_phase_1']:\n",
    "    df_discharge_target = pd.read_csv(f'./physionet.org/files/discharge-me/1.2/{subset}/discharge_target.csv.gz', keep_default_na=False)\n",
    "    df_discharge = pd.read_csv(f'./physionet.org/files/discharge-me/1.2/{subset}/discharge.csv.gz', keep_default_na=False)\n",
    "    df_radiology = pd.read_csv(f'./physionet.org/files/discharge-me/1.2/{subset}/radiology.csv.gz', keep_default_na=False)\n",
    "    df_diagnoses_ed = pd.read_csv(f'./physionet.org/files/discharge-me/1.2/{subset}/diagnosis.csv.gz', keep_default_na=False)\n",
    "    df_triage_ed = pd.read_csv(f'./physionet.org/files/discharge-me/1.2/{subset}/triage.csv.gz', keep_default_na=False)\n",
    "    df_stays_ed = pd.read_csv(f'./physionet.org/files/discharge-me/1.2/{subset}/edstays.csv.gz', keep_default_na=False)\n",
    "#     dfs[subset] = df_discharge.merge(df_discharge_target, on=['note_id', 'hadm_id'])    \n",
    "\n",
    "    merged_df = merge_two_dfs_no_dup_cols(df_discharge, df_discharge_target, ['hadm_id'])\n",
    "    merged_df = merge_two_dfs_no_dup_cols(merged_df, df_radiology.rename(columns={'text': 'radiology_text'}), ['hadm_id'])\n",
    "    merge_col = merged_df.drop(columns=['radiology_text']).columns.tolist()\n",
    "    merged_df = merged_df.groupby(merge_col).agg({\n",
    "        'radiology_text': lambda x: x.tolist()\n",
    "    }).reset_index()\n",
    "    \n",
    "    merged_df_2 = merge_two_dfs_no_dup_cols(df_stays_ed, df_triage_ed, ['stay_id', 'subject_id'])\n",
    "    merged_df_2 = merge_two_dfs_no_dup_cols(merged_df_2, df_diagnoses_ed, ['stay_id', 'subject_id'])\n",
    "    merge_col_2 = [col for col in merged_df_2.columns if col not in df_diagnoses_ed.drop(columns=['stay_id', 'subject_id']).columns]\n",
    "    agg_col_2 = {col: lambda x: x.tolist() for col in df_diagnoses_ed.drop(columns=['stay_id', 'subject_id']).columns}\n",
    "    merged_df_2 = merged_df_2.groupby(merge_col_2).agg(agg_col_2).reset_index()\n",
    "    \n",
    "    final_merged_df = merged_df.merge(merged_df_2)\n",
    "    dfs[subset] = final_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf46e8",
   "metadata": {},
   "source": [
    "## Remove Target from the Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce7d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_output_from_input(row):\n",
    "    row['new_text'] = row['text'].replace(row['brief_hospital_course'], '')\n",
    "    row['new_text'] = re.sub(r'Brief Hospital Course:\\n*', r'', row['new_text'], flags=re.DOTALL)\n",
    "    \n",
    "    row['new_text'] = row['new_text'].replace(row['discharge_instructions'], '')\n",
    "    row['new_text'] = re.sub(r'Discharge Instructions:\\n*', r'', row['new_text'], flags=re.DOTALL)\n",
    "    \n",
    "    row['new_text'] = re.sub(r'(\\n ?)+(Followup Instructions)', r'\\n\\n\\n\\2', row['new_text'], flags=re.DOTALL)\n",
    "    \n",
    "    return row\n",
    "    \n",
    "discharge = discharge.apply(remove_output_from_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2961be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, df in dfs.items():\n",
    "    dfs[domain] = dfs[domain].apply(remove_output_from_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7ccf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, df in dfs.items():\n",
    "    dfs[domain] = dfs[domain].rename(columns={'new_text': 'processed_text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366f961",
   "metadata": {},
   "source": [
    "## Remove Target Less than 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "700a5692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>text</th>\n",
       "      <th>brief_hospital_course</th>\n",
       "      <th>brief_hospital_course_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>pain</th>\n",
       "      <th>resprate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>icd_title</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [note_id, subject_id, hadm_id, note_type, note_seq, charttime, storetime, text, brief_hospital_course, brief_hospital_course_word_count, discharge_instructions, discharge_instructions_word_count, radiology_text, stay_id, intime, outtime, gender, race, arrival_transport, disposition, acuity, chiefcomplaint, dbp, heartrate, o2sat, pain, resprate, sbp, temperature, seq_num, icd_code, icd_version, icd_title, processed_text]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['train'][dfs['train']['discharge_instructions_word_count'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9576b2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>text</th>\n",
       "      <th>brief_hospital_course</th>\n",
       "      <th>brief_hospital_course_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>pain</th>\n",
       "      <th>resprate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>icd_title</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [note_id, subject_id, hadm_id, note_type, note_seq, charttime, storetime, text, brief_hospital_course, brief_hospital_course_word_count, discharge_instructions, discharge_instructions_word_count, radiology_text, stay_id, intime, outtime, gender, race, arrival_transport, disposition, acuity, chiefcomplaint, dbp, heartrate, o2sat, pain, resprate, sbp, temperature, seq_num, icd_code, icd_version, icd_title, processed_text]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['train'][dfs['train']['brief_hospital_course_word_count'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "160ce411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>text</th>\n",
       "      <th>brief_hospital_course</th>\n",
       "      <th>brief_hospital_course_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>pain</th>\n",
       "      <th>resprate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>icd_title</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [note_id, subject_id, hadm_id, note_type, note_seq, charttime, storetime, text, brief_hospital_course, brief_hospital_course_word_count, discharge_instructions, discharge_instructions_word_count, radiology_text, stay_id, intime, outtime, gender, race, arrival_transport, disposition, acuity, chiefcomplaint, dbp, heartrate, o2sat, pain, resprate, sbp, temperature, seq_num, icd_code, icd_version, icd_title, processed_text]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['train'][(dfs['train']['discharge_instructions_word_count'] < 10) | \n",
    "             (dfs['train']['brief_hospital_course_word_count'] < 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6615080",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, df in dfs.items():\n",
    "    mask = (dfs[domain]['discharge_instructions_word_count'] >= 10)\n",
    "    mask &= (dfs[domain]['brief_hospital_course_word_count'] >= 10)\n",
    "    dfs[domain] = dfs[domain][mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1bc855",
   "metadata": {},
   "source": [
    "## Export some sample discharge summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "\n",
    "top = 10\n",
    "for i, row in dfs['train'].reset_index(drop=True).head(top).iterrows():\n",
    "    document = Document()\n",
    "    \n",
    "    style = document.styles['Normal']\n",
    "    font = style.font\n",
    "    font.name = 'Courier New'\n",
    "    font.size = Pt(10.5)\n",
    "    style.paragraph_format.line_spacing = 1\n",
    "    style.paragraph_format.space_after = Pt(0)\n",
    "\n",
    "    \n",
    "#     document.add_paragraph(row['processed_text'], style=style)\n",
    "    for line in row['processed_text'].split(\"\\n\"):\n",
    "#         if line.strip() != '':\n",
    "#         if len(line) > 0:\n",
    "        document.add_paragraph(line, style=style)\n",
    "\n",
    "    document.save(f'discharge_summary_samples/discharge_summary_{i}.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197c5bf",
   "metadata": {},
   "source": [
    "# Section Extraction (Parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7afeee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "input_sections = OrderedDict([\n",
    "    ('Allergies', 'Allergies'),\n",
    "    ('Chief Complaint', '(?:Chief|_+) Complaint'),\n",
    "    ('Major Surgical or Invasive Procedure', '(?:Major |_+ *)(?:Surgical |_+ *)(?:or |_+ *)(?:Invasive|_+ *) Procedure'),\n",
    "    ('History of Present Illness', '(?:History|_+) of Present Illness'),\n",
    "    ('Past Medical History', '(?:Past|_+) Medical History'),\n",
    "    ('Social History', '(?:Social|_+) History'),\n",
    "    ('Family History', '(?:Family|_+) History'),\n",
    "    ('Physical Exam', 'Physical [A-Za-z_]+'),\n",
    "    ('Pertinent Results', '(?:Pertinent|_+) Results'),\n",
    "    ('Brief Hospital Course', 'Brief Hospital Course'),\n",
    "    ('Medications on Admission', '[A-Za-z_]+ on Admission'),\n",
    "    ('Discharge Medications', '[A-Za-z_]+ Medications'),\n",
    "    ('Discharge Disposition', '[A-Za-z_]+ Disposition'),\n",
    "    ('Discharge Diagnosis', '[A-Za-z_]+ Diagnosis'),\n",
    "    ('Discharge Condition', '[A-Za-z_]+ Condition')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6238b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SECTIONS REPORT\n",
    "s_list = []\n",
    "for section in input_sections.keys():\n",
    "    print(\"======\", section.upper(), \"======\")\n",
    "    s = pd.Series()\n",
    "    s.name = section\n",
    "    for subset in ['train', 'valid', 'test']:\n",
    "        size = dfs[subset].shape[0]\n",
    "        filtered_size = dfs[subset][dfs[subset]['text'].str.contains(section)].shape[0]\n",
    "        print(subset.upper(), size, filtered_size, filtered_size / size)\n",
    "        s[subset] = filtered_size / size\n",
    "    s_list += [s]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(s_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62fa4a1",
   "metadata": {},
   "source": [
    "## Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4683ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sections(row):\n",
    "    discharge_summary = row['text']\n",
    "    \n",
    "    for i, (section_name, section) in enumerate(input_sections.items()):\n",
    "        if section_name in ['Pertinent Results', 'Physical Exam', 'Brief Hospital Course', 'Past Medical History', 'Social History', 'Family History']:\n",
    "            for next_section in list(input_sections.values())[i+1:]:\n",
    "#                 regexp = re.compile(next_section)\n",
    "#                 if regexp.search(discharge_summary):\n",
    "#                     break\n",
    "#             print(\"Next Section: \", next_section)\n",
    "                search = re.findall(section + \".+\\n\" + next_section, discharge_summary, re.DOTALL)\n",
    "                if len(search) > 0:\n",
    "                    break\n",
    "\n",
    "#             rex = r'(%s?):\\s*\\n{0,2}(.+?)\\s*(\\n\\s*){2,10}(%s):(\\n[^=\\n])' % (section, next_section)\n",
    "            rex = r'(%s?):\\s*\\n{0,2}(.+?)\\s*(\\n\\s*){1,10}(%s):\\n' % (section, next_section)\n",
    "        else:\n",
    "#             rex = r'(%s?):\\s*\\n{0,2}(.+?)\\s*(\\n\\s*){2,10}((?:[A-Z][a-z ]+)+):(\\n[^=\\n])' % (section)\n",
    "#             rex = r'(%s?):\\s*\\n{0,2}(.+?)\\s*(\\n\\s*){1,10}((?:[A-Z][a-z ]+)+):\\n' % (section)\n",
    "            rex = r'(%s?):\\s*\\n{0,2}(.+?)\\s*(\\n\\s*){1,10}((?:[A-Z][a-z ]+)+):' % (section)\n",
    "\n",
    "#             rex = r'(%s?):\\s*\\n{1,2}(?!_+)(.+?)\\s*(\\n\\s*){2,10}((?:[A-Z][a-z ]+)+):(\\n[^=\\n])' % (section)\n",
    "                    \n",
    "        section_ext = re.findall(rex, discharge_summary, re.DOTALL)\n",
    "        section_col_name = section_name.replace(\" \", \"_\")\n",
    "        if len(section_ext) > 0:\n",
    "            row[section_col_name] = section_ext[-1]\n",
    "        else:\n",
    "            row[section_col_name] = np.nan\n",
    "            \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d7f5cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b068163d09e45f787026cf71cce7d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=6858), Label(value='0 / 6858'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for subset in ['train', 'valid', 'test']:\n",
    "for subset in ['train']:\n",
    "    dfs[subset] = dfs[subset].parallel_apply(parse_sections, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ea19319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461d035593f74620bed0c5b5cc59ef20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1468), Label(value='0 / 1468'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for subset in ['valid']:\n",
    "    dfs[subset] = dfs[subset].parallel_apply(parse_sections, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fd8d256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1d736a50624ef68eacff2de9e9fe0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1474), Label(value='0 / 1474'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for subset in ['test']:\n",
    "    dfs[subset] = dfs[subset].parallel_apply(parse_sections, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8cfc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6555847bc144317b3b6f0cb63e64332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1099), Label(value='0 / 1099'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for subset in ['test_2']:\n",
    "    dfs[subset] = dfs[subset].parallel_apply(parse_sections, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa6ff1",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9acc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in ['train', 'valid', 'test']:\n",
    "    dfs[subset] = dfs[subset].drop(columns=['__index_level_0__'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "917b4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/an/anaconda3/envs/deep_learning_env_2/lib/python3.9/site-packages/pyarrow/pandas_compat.py:358: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "discharge_data = DatasetDict({\n",
    "    'train': Dataset.from_pandas(dfs['train']),\n",
    "    'valid': Dataset.from_pandas(dfs['valid']),\n",
    "    'test': Dataset.from_pandas(dfs['test'])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d72b6ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4967a438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abe17e2680e441a84dcc0b28f48e45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/6 shards):   0%|          | 0/68574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef687ca069141b088caf3fd6e29d6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/14675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f026cf30724c41a7b70f247efab86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/14731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discharge_data.save_to_disk(\"discharge-data-save-sections-extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374e88a",
   "metadata": {},
   "source": [
    "## Read Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44aaa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_data = DatasetDict.load_from_disk(\"./discharge-data-save-sections-extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8854e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for subset, data in discharge_data.items():\n",
    "    data.set_format(\"pandas\")\n",
    "    dfs[subset] = data[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed7ea5",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ab77b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Allergies',\n",
       " 'Chief_Complaint',\n",
       " 'Major_Surgical_or_Invasive_Procedure',\n",
       " 'History_of_Present_Illness',\n",
       " 'Past_Medical_History',\n",
       " 'Social_History',\n",
       " 'Family_History',\n",
       " 'Physical_Exam',\n",
       " 'Pertinent_Results',\n",
       " 'Brief_Hospital_Course',\n",
       " 'Medications_on_Admission',\n",
       " 'Discharge_Medications',\n",
       " 'Discharge_Disposition',\n",
       " 'Discharge_Diagnosis',\n",
       " 'Discharge_Condition']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "input_sections = OrderedDict([\n",
    "    ('Allergies', 'Allergies'),\n",
    "    ('Chief Complaint', '(?:Chief|_+) Complaint'),\n",
    "    ('Major Surgical or Invasive Procedure', '(?:Major |_+ *)(?:Surgical |_+ *)(?:or |_+ *)(?:Invasive|_+ *) Procedure'),\n",
    "    ('History of Present Illness', '(?:History|_+) of Present Illness'),\n",
    "    ('Past Medical History', '(?:Past|_+) Medical History'),\n",
    "    ('Social History', '(?:Social|_+) History'),\n",
    "    ('Family History', '(?:Family|_+) History'),\n",
    "    ('Physical Exam', 'Physical [A-Za-z_]+'),\n",
    "    ('Pertinent Results', '(?:Pertinent|_+) Results'),\n",
    "    ('Brief Hospital Course', 'Brief Hospital Course'),\n",
    "    ('Medications on Admission', '[A-Za-z_]+ on Admission'),\n",
    "    ('Discharge Medications', '[A-Za-z_]+ Medications'),\n",
    "    ('Discharge Disposition', '[A-Za-z_]+ Disposition'),\n",
    "    ('Discharge Diagnosis', '[A-Za-z_]+ Diagnosis'),\n",
    "    ('Discharge Condition', '[A-Za-z_]+ Condition')\n",
    "])\n",
    "[col.replace(\" \", \"_\") for col in input_sections.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a7e64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Allergies',\n",
       " 'Chief_Complaint',\n",
       " 'Major_Surgical_or_Invasive_Procedure',\n",
       " 'History_of_Present_Illness',\n",
       " 'Past_Medical_History',\n",
       " 'Social_History',\n",
       " 'Family_History',\n",
       " 'Physical_Exam',\n",
       " 'Pertinent_Results',\n",
       " 'Brief_Hospital_Course',\n",
       " 'Medications_on_Admission',\n",
       " 'Discharge_Medications',\n",
       " 'Discharge_Disposition',\n",
       " 'Discharge_Diagnosis',\n",
       " 'Discharge_Condition']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections_col = [col.replace(\" \", \"_\") for col in input_sections.keys()]\n",
    "sections_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f71aed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in ['train', 'valid', 'test', 'test_2']:\n",
    "    for col in sections_col:\n",
    "        mask = pd.notnull(dfs[subset][col])\n",
    "        dfs[subset].loc[mask, col] = dfs[subset].loc[mask, col].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b26c04",
   "metadata": {},
   "source": [
    "# Diagnose Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9b1808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive_field = ['Physical_Exam', 'Pertinent_Results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25eb2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_count(row):\n",
    "    discharge_sections = []\n",
    "    for col in extractive_field:\n",
    "        word_count = 0\n",
    "        if pd.notnull(row[col]):\n",
    "            word_count = len(row[col].split(\" \"))\n",
    "        else:\n",
    "            word_count = 0\n",
    "        row[col+\"_Word_Count\"] = word_count\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4805ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in ['train', 'valid', 'test']:\n",
    "    dfs[subset] = dfs[subset].apply(calculate_word_count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad3112c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['train']['Physical_Exam_Word_Count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57dfaa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29096.000000\n",
       "mean       440.001306\n",
       "std        446.843602\n",
       "min          1.000000\n",
       "25%        161.000000\n",
       "50%        311.000000\n",
       "75%        567.000000\n",
       "max       6670.000000\n",
       "Name: Pertinent_Results_Word_Count, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['train']['Pertinent_Results_Word_Count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2862749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7b9c6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e085abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "dfs['test'] = pd.read_pickle(\"./discharge_data_test_set.pkl\")\n",
    "dfs['test_2'] = pd.read_pickle(\"./discharge_data_test_set_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73488eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db65a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(model, prompt, max_tokens, temperature=0, max_new_tokens=500):\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0,  # this is the degree of randomness of the model's output\n",
    "        request_timeout=1200\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed290b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "openai.api_key = \"EMPTY\" # Not support yet\n",
    "openai.api_base = \"http://localhost:8000/v1\"\n",
    "model = \"Mistral-7B-Instruct-v0.2-GPTQ-Brief-Hospital-Course\"\n",
    "prompt = \"Once upon a time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b7b0b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time[there was] [a] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p] [p]\n"
     ]
    }
   ],
   "source": [
    "# create a completion\n",
    "completion = openai.Completion.create(model=model, prompt=prompt, max_tokens=64, temperature=0)\n",
    "# print the completion\n",
    "print(prompt + completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69888afc",
   "metadata": {},
   "source": [
    "# Target Section Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145d058",
   "metadata": {},
   "source": [
    "## Brief Hospital Course Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247ffdb1",
   "metadata": {},
   "source": [
    "### Inference (API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13baf4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD 1 (CoT)\n",
    "brief_hospital_course_prompt = \"\"\"<s>[INST] In this task, you are provided with a Discharge Summary delimited by triple quotes.\n",
    "Discharge Summaries are documents that outline the care a patient received during their hospital stay, including diagnoses, treatments, and follow-up care instructions, prepared at the time of a patient's discharge. \n",
    "Discharge Summaries are split into various sections and written under a variety of headings, relating to admission, diagnosis and relevant discharge information. But the provided Discharge summary will be missing the \\\"Brief Hospital Course\\\". \\\"Brief Hospital Course\\\" is a section of the discharge summaries that outlines the key events of a patient's hospital stay, including the progression from admission to discharge. It is written for the subsequent care providers about the critical aspects of the patient.\n",
    "You are tasked to generate the missing \\\"Brief Hospital Course\\\" section in the discharge summary, based on the information of other sections in the discharge summary.\n",
    "Brief Hospital Course outlines the key events of a patient's hospital stay, including the progression from admission to discharge. It is written for the subsequent care providers about the critical aspects of the patient\n",
    "\n",
    "The summary should be written in the following structure, by answering some important questions:\n",
    "1. Initial presentation: Describe the patient's initial presentation, including the main complaint and relevant history.\n",
    "    * What were the main treatment strategies employed for the patient's conditions during their stay? Include medications adjusted, procedures performed, and any therapeutic interventions.\n",
    "    * What are the key diagnoses identified during the hospital stay?\n",
    "2. Treatment course:\n",
    "    - For each section header named by \"#Condition Name\", provide a detailed description of each condition, disease, or symptom of the patient by answering the following questions:\n",
    "        * What is the patient's background relating to the condition, disease, or symptom\n",
    "        * Describe the treatment strategy, including any medications given, procedures performed, and dietary adjustments.\n",
    "        * How was the diagnosis reached, including any significant tests or evaluations conducted?\n",
    "        * What were the significant medical or surgical interventions during the hospital stay, including any procedures, diagnostic tests (e.g., CT Scan, Imaging, Blood Test, MRI), and changes in medication?\n",
    "        * Were there any complications or additional diagnoses during the hospital stay? How were these addressed and managed?\n",
    "        * How did the patient's condition progress throughout the hospital stay, including any monitoring of symptoms, response to treatments, and adjustments made to the treatment plan?\n",
    "        * What were the conditions and considerations for the patient’s discharge? Include the discharge medications, any changes from previous medication regimens, and follow-up care or lifestyle recommendations.\n",
    "3. Transitional issues: Highlight any transitional care issues addressed during the hospital stay, including changes in medication, dietary adjustments, and specific care instructions.\n",
    "4. Acute/active issues: Detail the management of acute or active issues encountered during the stay, using the provided structure for each condition.\n",
    "5. Chronic/stable issues: Summarize how chronic conditions were managed during the stay and any adjustments made to long-term management plans.[/INST]</s>\n",
    "\n",
    "[INST] Discharge summary: \n",
    "\\\"\\\"\\\"%s\\\"\\\"\\\" [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a74b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(model, prompt, max_tokens, temperature=0):\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0,  # this is the degree of randomness of the model's output\n",
    "        request_timeout=2000\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81820505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_section(my_prompt, data, model=\"checkpoint-87288\"):\n",
    "    final_prompt = my_prompt % data\n",
    "\n",
    "    retries = 5\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            response = get_completion(model, final_prompt, 1000, temperature=0)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            if e:\n",
    "                if \"exceeded your current quota\" in str(e).lower():\n",
    "                    raise e\n",
    "                print(e)\n",
    "                print('Timeout error, retrying...')\n",
    "                retries -= 1\n",
    "                if \"limit reached for\" in str(e).lower():\n",
    "                    time.sleep(30)\n",
    "                else:\n",
    "                    time.sleep(5)\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    print('API is not responding, moving on...')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3974ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_section_summarization(root_path, target_section_prompt, output_col_name, domain, domain_df, model, save_step=10):\n",
    "\n",
    "    src_path = f\"{root_path}/{domain}\"\n",
    "    Path(src_path).mkdir(parents=True, exist_ok=True)\n",
    "    extractions = []\n",
    "\n",
    "    file_names = listdir(src_path)\n",
    "    postfix = [re.split(\"[_.]\", name)[1]\n",
    "               for name in listdir(src_path)\n",
    "               ]\n",
    "    start = 0\n",
    "    if 'done' in postfix:\n",
    "        print(domain, \": \", \"Loaded saved file. Done\")\n",
    "        new_domain_df = pd.read_pickle(f\"{src_path}/{domain}_done.pkl\")\n",
    "        return new_domain_df\n",
    "    elif len(postfix) > 0:\n",
    "        last_index = max([int(idx) for idx in postfix if idx != 'done'])\n",
    "        last_domain_df = pd.read_pickle(f\"{src_path}/{domain}_{last_index}.pkl\")\n",
    "        extractions = last_domain_df[output_col_name].tolist()\n",
    "        start = last_index\n",
    "        print(domain, \"Loaded saved file. Continuing\")\n",
    "    else:\n",
    "        print(domain, \"Start new process.\")\n",
    "\n",
    "    for i, (_, row) in tqdm(enumerate(domain_df.iterrows()), total=domain_df.shape[0]):\n",
    "        if i < start:\n",
    "            continue\n",
    "\n",
    "        discharge_summary_data = row['processed_text']\n",
    "        extraction = generate_target_section(target_section_prompt, discharge_summary_data, model)\n",
    "        time.sleep(0.3)\n",
    "        extractions += [extraction]\n",
    "\n",
    "        if (i + 1) % save_step == 0:\n",
    "            save_df = domain_df.iloc[:i + 1]\n",
    "            save_df.insert(0, output_col_name, extractions)\n",
    "            save_df[['hadm_id', output_col_name]].to_pickle(f\"{src_path}/{domain}_{i + 1}.pkl\")\n",
    "\n",
    "    new_domain_df = domain_df.iloc[:i + 1]\n",
    "    new_domain_df.insert(0, output_col_name, extractions)\n",
    "    new_domain_df[['hadm_id', output_col_name]].to_pickle(f\"{src_path}/{domain}_done.pkl\")\n",
    "    return new_domain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a725a3e",
   "metadata": {},
   "source": [
    "### Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "148a83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs['test_2']\n",
    "df['processed_text_word_count'] = df['processed_text'].apply(lambda x: len(x.split(\" \")))\n",
    "df = df.sort_values(by=['processed_text_word_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14557373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thres = 1000\n",
    "# thres = 1200\n",
    "# thres = 1500\n",
    "df['category'] = df['processed_text_word_count'].apply(lambda x: 1 if x < thres else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed68a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['processed_text_word_count'] >= 1000) & (df['processed_text_word_count'] <= 1300)\n",
    "df.loc[mask, 'category'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e41143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (df['processed_text_word_count'] >= 1000) & (df['processed_text_word_count'] <= 1150)\n",
    "# df.loc[mask, 'category'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88432b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0    5049\n",
       "1    3436\n",
       "2    2500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c254a",
   "metadata": {},
   "source": [
    "#### R128_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1f183cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pertinent_results_with_radiology(row):\n",
    "    if pd.notnull(row['Pertinent_Results']):\n",
    "        new_reports = []\n",
    "        for report in row['radiology_text']:\n",
    "            rex = r'((?i)impression:[\\s ]*\\n{0,2}(.+?)\\s*$)'\n",
    "            section_ext = re.findall(rex, report, re.DOTALL)\n",
    "            if len(section_ext) > 0 and section_ext[0][1][:15] in row['Pertinent_Results']:\n",
    "                new_reports += [report]\n",
    "        \n",
    "        new_pertinent_results = \"=============\\n\\n\".join([report for report in new_reports])\n",
    "        row['processed_text'] = row['processed_text'].replace(row['Pertinent_Results'], new_pertinent_results)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4a9f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pertinent_results_with_radiology(row):\n",
    "    if pd.notnull(row['Pertinent_Results']):\n",
    "        new_reports = []\n",
    "        for report in row['radiology_text']:\n",
    "            rex = r'((?i)impression:[\\s ]*\\n{0,2}(.+?)\\s*$)'\n",
    "            section_ext = re.findall(rex, report, re.DOTALL)\n",
    "            if len(section_ext) > 0 and section_ext[0][1][:15] in row['Pertinent_Results']:\n",
    "                new_reports += [report]\n",
    "        \n",
    "        new_pertinent_results = \"\"\n",
    "#         new_reports.sort(key=len, reverse=True)\n",
    "        for report in new_reports:\n",
    "            if len(new_pertinent_results.split(\" \")) == 1:\n",
    "                new_pertinent_results += report\n",
    "            elif len(new_pertinent_results.split(\" \")) < 1000:\n",
    "                new_pertinent_results += (\"=============\\n\\n\" + report)\n",
    "#         new_pertinent_results = \"=============\\n\\n\".join([report for report in new_reports])\n",
    "        new_pertinent_results += \"=============\\n\\n\"\n",
    "    \n",
    "        row['processed_text'] = row['processed_text'].replace(row['Pertinent_Results'], new_pertinent_results)\n",
    "            \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06e2ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26792/1835229656.py:6: DeprecationWarning: Flags not at the start of the expression '((?i)impression:[\\\\s ' (truncated) but at position 1\n",
      "  section_ext = re.findall(rex, report, re.DOTALL)\n"
     ]
    }
   ],
   "source": [
    "df = df.apply(replace_pertinent_results_with_radiology, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0302a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491\n"
     ]
    }
   ],
   "source": [
    "print(len(df.iloc[0]['processed_text'].split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ec650a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = './discharge_me_output/brief_hospital_course_mistral_finetuned_phase_2_r128_64_new_pertinent_2'\n",
    "root_path = './discharge_me_output/brief_hospital_course_mistral_finetuned_phase_2_r128_64_new_pertinent_2_plain_best'\n",
    "# num_workers = 2\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85eb56e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint-11838'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "622b0faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Loaded saved file. Continuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3436/3436 [26:31:22<00:00, 27.79s/it]\n"
     ]
    }
   ],
   "source": [
    "inputs = [(root_path,\n",
    "           brief_hospital_course_prompt,\n",
    "           'Brief_Hospital_Course_Generated',\n",
    "           domain,\n",
    "           df[df['category'] == domain].reset_index(drop=True),\n",
    "           model,\n",
    "           10,\n",
    "           )\n",
    "          for domain in [1]]\n",
    "#           for domain in [0, 1]]\n",
    "start_time = time.time()\n",
    "with Pool(num_workers) as processor:\n",
    "    data = processor.starmap(target_section_summarization, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33d551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
